{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atH1LFklzTeL"
      },
      "source": [
        "1. Load important packages and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZApU4PmLzTeM"
      },
      "outputs": [],
      "source": [
        "#---------- Importing useful packages --------------#\n",
        "import torch # pytorch main library\n",
        "import glob\n",
        "import torchvision # computer vision utilities\n",
        "import torchvision.transforms as transforms # transforms used in the pre-processing of the data\n",
        "from torchvision import *\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set paths to retrieve data\n",
        "TRAIN_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Train\"\n",
        "VAL_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Validation\"\n",
        "TEST_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Test\""
      ],
      "metadata": {
        "id": "qiPmYBNr96I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ImZDgWzTeN"
      },
      "source": [
        "2. Data Loading and Pre-processing\n",
        "    - Padded the images so they are square\n",
        "    - Resized the images to a managable size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDRjvbj2zTeN"
      },
      "outputs": [],
      "source": [
        "# Pre processing for ResNet-50. Inputs and output sizes,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ7WPx4jzTeO"
      },
      "source": [
        "3. Experimental setup\n",
        "    -   Single train/val/test split: 70%/ 15%/ 15%\n",
        "    -   Set data augmentation\n",
        "    -   Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HffA5CrzTeP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K_biB2EzTeP"
      },
      "source": [
        "\n",
        "4. Transfer learning\n",
        "    - SOTA models on imagenet\n",
        "    - Add and train new top/predictor\n",
        "    - Fine-tune all or some feature learning layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYuvQXVHzTeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxTNX6VHzTeQ"
      },
      "source": [
        "5. Loss and metrics\n",
        "    -   Loss: categorical cross-entropy\n",
        "    -   Metrics: Accuracy, sensitivity, specificity, confusion matrix, training and inference time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za7F2nb2zTeR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4_IddF6zTeS"
      },
      "source": [
        "6. Set your callbacks and track your experiments\n",
        "    - Early stopping - patience\n",
        "    - Model check point\n",
        "    - Learning rate scheduler\n",
        "    - Weights and biases (train/val loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNqBBXJ5zTeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "occhqt8bzTeS"
      },
      "source": [
        "7. Set your main hyperparameters\n",
        "    - batch size\n",
        "    - learning rate\n",
        "    - number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5iu4J-zzTeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sad-Id7VzTeT"
      },
      "source": [
        "8. Train\n",
        "    - Train your model\n",
        "    - Need to write your training code in pure Python and PyTorch or use another library like lightning or ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGGpP4rzTeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQbLhn5azTeT"
      },
      "source": [
        "9. Test\n",
        "    - Run prediction on your test set\n",
        "    - Extract relevant metrics\n",
        "    - Measure inference time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7d389tEzTeT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Classification Model\n",
    "\n",
    "This assignment follows the model proposed in assignment 1 to solve the garbage classification problem. The notebook highlights the predictions from the model and the rasoning behind decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data came pre-split with the assignment instructions.\n",
    "Number of images in the training folder creates the batch size when training\n",
    "Initial number of epochs was set arbitrarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To solve this problem, a custom dataset was created and a MultiModal model was implemented\n",
    "1. Read data and create numpy arrays of images, text and labels associated.\n",
    "\n",
    "2. Data pre-processing\n",
    "- Custom dataset was created. This outputs the images, labels, text, attetion mask and input ids.\n",
    "The transformation resizes image and applies normalization using statistics based on ResNet training.\n",
    "- Data Loader was created\n",
    "\n",
    "3. Model created\n",
    "- The model uses ResNet50 and BERT as the feature extraction backbone.\n",
    "- A dense layer is added after each to ensure both input similar number of features. This was normalized and the ReLu activation function added.\n",
    "- The text and image feature was merged and passed through the final classification layer.\n",
    "- a log_softmax was used at the end as the output.\n",
    "\n",
    "![Garbage Classification Model](./Assignment2.png)\n",
    "\n",
    "4. Training and Validation\n",
    "- Batch size, learning rate, number of epochs were the main hyperparameters changed\n",
    "- Early stopping after 5 iterations with no change during training was introduced to the model after noticing  overfitting. The AdamW optimizer with weight decay was used.\n",
    "- With an imbalanced dataset, a weighted CrossEntropy Loss was used. The class distribution of the training set was:\n",
    "![Garbage Classification Model](./ClassDistribution.png)\n",
    "\n",
    "This notebook runs the test section of the code with the best model. Results for testing is given by accuracy, F1 score and the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Self' from 'typing_extensions' (C:\\Users\\Veron\\anaconda3\\lib\\site-packages\\typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8ec234c82c81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Import necessary functions from python files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Model, Custom dataset and data extraction function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mData_and_Model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_text_files_with_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGarbageModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\GitHub\\ENEL645\\Assignment 2\\Submit\\Data_and_Model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# useful packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#---------- Importing useful packages --------------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;31m# pytorch main library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;31m# computer vision utilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1477\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lowrank\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvd_lowrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca_lowrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m from .overrides import (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m from .parameter import (\n\u001b[0;32m      3\u001b[0m     \u001b[0mParameter\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mUninitializedBuffer\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUninitializedBuffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mConvTranspose1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConvTranspose2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConvTranspose3d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mLazyConv1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyConv2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyConv3d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyConvTranspose1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyConvTranspose2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLazyConvTranspose3d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Self' from 'typing_extensions' (C:\\Users\\Veron\\anaconda3\\lib\\site-packages\\typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "# Importing important functions and modules\n",
    "# Import necessary functions from python files\n",
    "# Model, Custom dataset and data extraction function\n",
    "from Data_and_Model import read_text_files_with_labels, CustomDataset, GarbageModel\n",
    "\n",
    "# Metrics\n",
    "from Metrics import metrics_eval\n",
    "\n",
    "#---------- Importing useful packages --------------#\n",
    "import torch # pytorch main library\n",
    "import glob\n",
    "import torchvision # computer vision utilities\n",
    "import torchvision.transforms as transforms # transforms used in the pre-processing of the data\n",
    "from torchvision import *\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18, resnet50, ResNet50_Weights\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "##-----------------------------------------------------------------------------------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set: 3431\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\ImageFile.py\", line 271, in load\n    s = read(self.decodermaxblock)\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 932, in load_read\n    cid, pos, length = self.png.read()\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 167, in read\n    length = i32(s)\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Veron\\OneDrive\\GitHub\\ENEL645\\Assignment 2\\Submit\\Data_and_Model.py\", line 81, in __getitem__\n    image = Image.open(self.image_paths[idx]).convert('RGB')\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\Image.py\", line 922, in convert\n    self.load()\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\ImageFile.py\", line 278, in load\n    raise OSError(msg) from e\nOSError: image file is truncated\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ##-----------------------------------------------------------------------------------------------------------##\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# get some random training images\u001b[39;00m\n\u001b[0;32m     29\u001b[0m pred_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(predloader)\n\u001b[1;32m---> 30\u001b[0m pred_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpred_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Visualizing a sample image from dataset\u001b[39;00m\n\u001b[0;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\ImageFile.py\", line 271, in load\n    s = read(self.decodermaxblock)\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 932, in load_read\n    cid, pos, length = self.png.read()\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\PngImagePlugin.py\", line 167, in read\n    length = i32(s)\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\_binary.py\", line 85, in i32be\n    return unpack_from(\">I\", c, o)[0]\nstruct.error: unpack_from requires a buffer of at least 4 bytes for unpacking 4 bytes at offset 0 (actual buffer size is 0)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Veron\\OneDrive\\GitHub\\ENEL645\\Assignment 2\\Submit\\Data_and_Model.py\", line 81, in __getitem__\n    image = Image.open(self.image_paths[idx]).convert('RGB')\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\Image.py\", line 922, in convert\n    self.load()\n  File \"c:\\Python38\\lib\\site-packages\\PIL\\ImageFile.py\", line 278, in load\n    raise OSError(msg) from e\nOSError: image file is truncated\n"
     ]
    }
   ],
   "source": [
    "# Set the hyperparameters\n",
    "batch_size = 256 # Change Batch Size o\n",
    "num_workers = 2\n",
    "\n",
    "# Extract data and create Data Loaders\n",
    "PRED_PATH = r\"./CVPR_2024_dataset_Test\" # Prediction images path\n",
    "\n",
    "torchvision_transform_test = transforms.Compose([transforms.Resize((224,224)),\\\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406] ,std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased') # BERT Tokenizer for caption text\n",
    "max_len = 24\n",
    "\n",
    "#Dataset has been pre-split, load all data sets.\n",
    "pred_dataset = CustomDataset(PRED_PATH, max_len, tokenizer, transform=torchvision_transform_test)\n",
    "\n",
    "# Get the data loader for the train set\n",
    "predloader = DataLoader(pred_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "#Dataset has been pre-split, load all data sets.\n",
    "pred_set_size = int(len(pred_dataset))\n",
    "\n",
    "#classes = ('green', 'blue', 'black', 'other')\n",
    "print(\"Prediction set:\", pred_set_size)\n",
    "\n",
    "# ##-----------------------------------------------------------------------------------------------------------##\n",
    "\n",
    "# get some random training images\n",
    "pred_iterator = iter(predloader)\n",
    "pred_batch = next(pred_iterator)\n",
    "\n",
    "# Visualizing a sample image from dataset\n",
    "plt.figure()\n",
    "plt.imshow(pred_batch['image'].numpy()[8].transpose(1,2,0).reshape(128, 128)) # Convert tensor to numpy array\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veron\\AppData\\Local\\Temp\\ipykernel_17668\\16072472.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(PATH))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./garbage_net731.pth\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# Path to save the best model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m net \u001b[38;5;241m=\u001b[39m GarbageModel(\u001b[38;5;241m4\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m), \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m metrics_eval(net, predloader, device) \u001b[38;5;66;03m# Plots the confusion matrix too\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\serialization.py:1072\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1070\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m   1071\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1072\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[0;32m   1074\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1076\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python38\\lib\\site-packages\\torch\\serialization.py:480\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[1;34m(self, name_or_buffer)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "# Loading the best model and predicting classes\n",
    "PATH = './garbage_net731.pth' # Path to save the best model\n",
    "net = GarbageModel(4, (3,224,224), False)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "metrics_eval(net, predloader, device) # Plots the confusion matrix too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the Misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTIONS\n",
    "# Plot the misclassified samples\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(224, 224), cmap='gray')\n",
    "    plt.title(' Predicted Bin= '+ str(data_sample[2]) + ' Actual Bin= ' + str(data_sample[1]))\n",
    "\n",
    "# label to word\n",
    "def bin(label):\n",
    "    if label == 0:\n",
    "        color = 'BLACK'\n",
    "    elif label == 1:\n",
    "        color = 'BLUE'\n",
    "    elif label == 2:\n",
    "        color = 'GREEN'\n",
    "    elif label == 3:\n",
    "        color = 'OTHER'\n",
    "    return color\n",
    "\n",
    "count = 0\n",
    "for batch in predloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    label = batch['label']\n",
    "    images = batch['image']\n",
    "    z = net(images, input_ids, attention_mask)\n",
    "    _, ypred = torch.max(z, 1)\n",
    "    if ypred != label:\n",
    "        plt.figure()\n",
    "        show_data((images, label, ypred))\n",
    "        plt.show()\n",
    "        count += 1\n",
    "    if count >= 5:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# References\n",
    "\n",
    "These were useful in writing the code, and implementing the model.\n",
    "\n",
    "1.   CNN Minst, and garbage classification tutorials\n",
    "2.   https://www.pluralsight.com/resources/blog/guides/introduction-to-resnet\n",
    "3. https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "4. Multimodal https://www.kaggle.com/code/fabraz/image-and-text-multimodal\n",
    "5. https://wandb.ai/mostafaibrahim17/ml-articles/reports/The-Basics-of-ResNet50---Vmlldzo2NDkwNDE2#pytorch\n",
    "6. Custom Data set looking at ImageFolder https://dilithjay.com/blog/custom-image-classifier-with-pytorch\n",
    "7. Handling imbalanced data: https://saturncloud.io/blog/how-to-use-class-weights-with-focal-loss-in-pytorch-for-imbalanced-multiclass-classification/\n",
    "8. Adam optimizer: https://www.datacamp.com/tutorial/adamw-optimizer-in-pytorch\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

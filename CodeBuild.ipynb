{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atH1LFklzTeL"
      },
      "source": [
        "## Missing areas\n",
        "> Make text data useful\n",
        "> redo Model\n",
        "\n",
        "1. Load important packages and Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZApU4PmLzTeM"
      },
      "outputs": [],
      "source": [
        "#---------- Importing useful packages --------------#\n",
        "import torch # pytorch main library\n",
        "import glob\n",
        "import torchvision # computer vision utilities\n",
        "import torchvision.transforms as transforms # transforms used in the pre-processing of the data\n",
        "from torchvision import *\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set paths to retrieve data\n",
        "TRAIN_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Train\"\n",
        "VAL_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Validation\"\n",
        "TEST_PATH = r\"C:\\Users\\rober\\OneDrive - University of Calgary\\Projects\\Garbage-classification\\CVPR_2024_dataset\\CVPR_2024_dataset\\Test\""
      ],
      "metadata": {
        "id": "qiPmYBNr96I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------- Important Functions -----------------------------------#\n",
        "\n",
        "# Extract text from file names as well as labels\n",
        "def read_text_files_with_labels(path):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    class_folders = sorted(os.listdir(path))  # Assuming class folders are sorted\n",
        "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            file_names = os.listdir(class_path)\n",
        "            for file_name in file_names:\n",
        "                file_path = os.path.join(class_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
        "                    text = file_name_no_ext.replace('_', ' ')\n",
        "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
        "                    texts.append(text_without_digits)\n",
        "                    labels.append(label_map[class_name])\n",
        "\n",
        "    return np.array(texts), np.array(labels)\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img,stats):\n",
        "    img = img *stats[1] + stats[0]     # unnormalize\n",
        "    npimg = img.numpy() # convert the tensor back to numpy\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "jyV0cLGUDLuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "occhqt8bzTeS"
      },
      "source": [
        "2. Set your main hyperparameters\n",
        "    - batch size\n",
        "    - learning rate\n",
        "    - number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the hyperparameters\n",
        "batch_size = 128 # Change Batch Size o\n",
        "learning_rate = 1e-3\n",
        "num_workers = 4\n",
        "nepochs = 20 #\"Use it to chane iterations\"\n",
        "best_loss = 1e+20"
      ],
      "metadata": {
        "id": "71XtqAupPfN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ImZDgWzTeN"
      },
      "source": [
        "3. Data Loading and Pre-processing and Experimental setup\n",
        "    -   Data already split\n",
        "    -   Set data augmentation\n",
        "    -   Create data loaders\n",
        "    - Padded the images so they are square\n",
        "    - Resized the images to a managable size\n",
        "\n",
        "Pay attention to text labels\n",
        "\n",
        "Use customdataset function to create a dataset with both images and text as label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDRjvbj2zTeN"
      },
      "outputs": [],
      "source": [
        "#------------ Data Loadinga and Pre-processing -------------------#\n",
        "# IMAGE\n",
        "# Convert the data to a PyTorch tensor\n",
        "\n",
        "torchvision_transform = transforms.Compose([transforms.Resize((224,224)),\\\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406] ,std=[0.229, 0.224, 0.225] )])\n",
        "\n",
        "\n",
        "torchvision_transform_test = transforms.Compose([transforms.Resize((224,224)),\\\n",
        "    transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406] ,std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "#Dataset has been pre-split, load all data sets.\n",
        "train_dataset = ImageFolder(root=TRAIN_PATH, transform= torchvision_transform)\n",
        "val_dataset = ImageFolder(root=VAL_PATH, transform= torchvision_transform)\n",
        "test_dataset = ImageFolder(root=TEST_PATH, transform= torchvision_transform_test)\n",
        "train_set_size = int(len(train_dataset))\n",
        "val_set_size = int(len(val_dataset))\n",
        "test_set_size = int(len(test_dataset))\n",
        "\n",
        "# Get the data loader for the train set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "\n",
        "classes = ('green', 'blue', 'black', 'other')\n",
        "\n",
        "print(class_names)\n",
        "print(\"Train set:\", train_set_size)\n",
        "print(\"Val set:\", val_set_size)\n",
        "print(\"Test set:\", test_set_size)\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:8]), stats)\n",
        "\n",
        "# Pre processing for ResNet-50. Inputs and output sizes,"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEXT\n",
        "# The file names will be extracted and used as labels\n",
        "\n",
        "\n",
        "# One- Hot Encoding is used to repressent labels for easy use of categorical cross- Entropy Loss."
      ],
      "metadata": {
        "id": "jibBo4AZKsbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))"
      ],
      "metadata": {
        "id": "R1o2bCj3LhNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K_biB2EzTeP"
      },
      "source": [
        "\n",
        "4. Transfer learning\n",
        "    - SOTA models on imagenet\n",
        "    - Add and train new top/predictor\n",
        "    - Fine-tune all or some feature learning layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYuvQXVHzTeQ"
      },
      "outputs": [],
      "source": [
        "#----------- Defining Model. -------------#\n",
        "# ResNet-50 being used as a fixed feature extractor and the last fully connected layer will be trained\n",
        "\n",
        "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "\n",
        "## Train and Eval\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "\n",
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "##  Transfer Learning of ResNet-50\n",
        "net = models.resnet18(pretrained=True)# Calling a pre-trained ResNet-50 model\n",
        "net = net.cuda() if device else net\n",
        "net\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss() # Loss function\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Optimizer used for training\n",
        "\n",
        "# Number of filters\n",
        "num_ftrs = net.fc.in_features\n",
        "net.fc = nn.Linear(num_ftrs, 128)\n",
        "net.fc = net.fc.cuda() if use_cuda else net.fc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GarbageModel(nn.Module):\n",
        "    def __init__(self,  num_classes, input_shape, transfer=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.transfer = transfer\n",
        "        self.num_classes = num_classes\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "        # transfer learning if weights=True\n",
        "        self.feature_extractor = models.resnet18(weights=transfer)\n",
        "\n",
        "        if self.transfer:\n",
        "            # layers are frozen by using eval()\n",
        "            self.feature_extractor.eval()\n",
        "            # freeze params\n",
        "            for param in self.feature_extractor.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        n_features = self._get_conv_output(self.input_shape)\n",
        "        self.classifier = nn.Linear(n_features, num_classes)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        batch_size = 1\n",
        "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
        "\n",
        "        output_feat = self.feature_extractor(tmp_input)\n",
        "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
        "        return n_size\n",
        "\n",
        "    # will be used during inference\n",
        "    def forward(self, x):\n",
        "       x = self.feature_extractor(x)\n",
        "       x = x.view(x.size(0), -1)\n",
        "       x = self.classifier(x)\n",
        "\n",
        "       return x\n"
      ],
      "metadata": {
        "id": "Lzsvw5SHrxFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = GarbageModel(4, (3,224,224), True)\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "CbQ7M__4rjqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxTNX6VHzTeQ"
      },
      "source": [
        "5. Loss and Callbacks\n",
        "    -   Loss: categorical cross-entropy\n",
        "    - Using the Adam Optimizer for it's adaptaive learning rate, over SGD becaue of computational time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za7F2nb2zTeR"
      },
      "outputs": [],
      "source": [
        "#------- Training Parameters ---------#\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss() # Loss function\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001) # Optimizer used for training\n",
        "#optimizer = optim.Adam(model.parameters(), lr=2e-5)# Optimizer used for training\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4_IddF6zTeS"
      },
      "source": [
        "6. Set your callbacks and track your experiments\n",
        "    - Early stopping - patience\n",
        "    - Model check point\n",
        "    - Learning rate scheduler\n",
        "    - Weights and biases (train/val loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNqBBXJ5zTeS"
      },
      "outputs": [],
      "source": [
        "PATH = './garbage_net.pth' # Path to save the best model\n",
        "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
        "    # Training Loop\n",
        "    train_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print(f'{epoch + 1},  train loss: {train_loss / i:.3f},', end = ' ')\n",
        "    scheduler.step()\n",
        "\n",
        "    val_loss = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "        print(f'val loss: {val_loss / i:.3f}')\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_loss:\n",
        "            print(\"Saving model\")\n",
        "            torch.save(net.state_dict(), PATH)\n",
        "            best_loss = val_loss\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sad-Id7VzTeT"
      },
      "source": [
        "8. Train\n",
        "    - Train your model\n",
        "    - Need to write your training code in pure Python and PyTorch or use another library like lightning or ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGGpP4rzTeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQbLhn5azTeT"
      },
      "source": [
        "9. Test\n",
        "    - Run prediction on your test set\n",
        "    - Extract relevant metrics\n",
        "    - Measure inference time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7d389tEzTeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics\n",
        "- Metrics: Accuracy, F1-score, confusion matrix, training and inference time?"
      ],
      "metadata": {
        "id": "sBgH2orfYzXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------- Metrics -------------#\n",
        "\n",
        "# ACCURACY\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "#def accuracy(out, labels):\n",
        "    _,pred = torch.max(out, dim=1)\n",
        "    return torch.sum(pred==labels).item()\n",
        "\"Check how to define Accuracy\"\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
        "\n",
        "\n",
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "\n",
        "\n",
        "##\n",
        "#plot Accuracy\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.title(\"Train-Validation Accuracy\")\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(val_acc, label='validation')\n",
        "plt.xlabel('num_epochs', fontsize=12)\n",
        "plt.ylabel('accuracy', fontsize=12)\n",
        "plt.legend(loc='best')\n",
        "\n",
        "def visualize_model(net, num_images=4):\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, data in enumerate(test_dataloader):\n",
        "        inputs, labels = data\n",
        "        if use_cuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = net(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        preds = preds.cpu().numpy() if use_cuda else preds.numpy()\n",
        "        for j in range(inputs.size()[0]):\n",
        "            images_so_far += 1\n",
        "            ax = plt.subplot(2, num_images//2, images_so_far)\n",
        "            ax.axis('off')\n",
        "            ax.set_title('predictes: {}'.format(test_dataset.classes[preds[j]]))\n",
        "            imshow(inputs[j])\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "                return\n",
        "\n",
        "plt.ion()\n",
        "visualize_model(net)\n",
        "plt.ioff()\n"
      ],
      "metadata": {
        "id": "zhkIEgzzY0EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# References\n",
        "CNN Minst tutorial\n",
        "https://www.pluralsight.com/resources/blog/guides/introduction-to-resnet\n",
        "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n"
      ],
      "metadata": {
        "id": "bvBEp_7FO0JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upsUlvFuOyn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}